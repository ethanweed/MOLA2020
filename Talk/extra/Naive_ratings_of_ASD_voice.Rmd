---
title: "Acoustic measures and peer ratings"
author: "Ethan Weed"
date: "10/28/2019"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Data preparation
```{r echo = T, results = 'hide', message=FALSE, warning = F}
rm(list = ls())

df <- read.csv("/Users/ethan/Documents/GitHub/ASD-voice/Paper/data/FullData2.csv")
df$X <- NULL
df$id <- NULL

df <- df[, c("ID","DX", "F0", "F0_SD", "creak", "creak_SD", "H1H2", "H1H2_SD", "utt_duration", "speech_rate", "articulation_rate", "jitter", "shimmer", "rating_clin", "rating_naive")]

```


# Typical vs. atypical voices
First, we visualize the networks of acoustic features of voices rated as "Typical" or "Atypical" by naïve raters. These groups overlap largely, but not entirely, with diagnosis
```{r echo = T, results = 'hide', message=FALSE, warning = F}
library(qgraph)

groups <- factor(c(rep("Prosody", 2), rep("Voice", 4), rep("Prosody", 3), rep("Voice", 2)))

d_high <- subset(df, rating_naive > 1.5)
d_high$rating_clin <- NULL
d_high$rating_naive <- NULL

d_low <- subset(df, rating_naive <= 1.5)
d_low$rating_clin <- NULL
d_low$rating_naive <- NULL
#qgraph(cor(df[,3:15]), layout = "spring", labels = colnames(df[,3:15]))

g_high <- qgraph(cor(d_high[,3:13]), layout = "spring", labels = colnames(d_high[,3:13]), groups = groups, title = "Atypical Speakers - correlation")
g_low <-qgraph(cor_auto(d_low[,3:13]), layout = "spring", labels = colnames(d_low[,3:13]), groups = groups, title = "Typical Speakers -  correlation")
```


## Which are the most important nodes?
Here, we measure "importance" as "betweenness centrality": the degree to which one would need to pass through any given node to reach any other given node. It is not clear that this is necessarily the best way to measure the importance of acoustic features in this context, but it has the advantage of at least being intuitively understandable. A Google Scholar search for "network of acoustic features" gives *zero* results, and a Google search for the same term results in only one reference: a book chapter on computer speech recognition. So there is not a lot of precedent to go on here. My thought here is to try to stay within the network paradigm, on the grounds that speech is a complex signal with many intercorrelated and sometimes redundant signals.
```{r echo = T, results = 'hide', message=FALSE, warning = F}
library(ggplot2)
library(qgraph)
library(tidyverse)

#centralityPlot(g_low)
#centralityPlot(g_high)

C_low <- centralityTable(g_low)
C_high <- centralityTable(g_high)

B_low <- subset(C_low, measure == "Betweenness")
B_high <- subset(C_high, measure == "Betweenness")

B_low$Typicality <- "Typical"
B_high$Typicality <- "Atypical"

B2 <- rbind(B_low, B_high)

ggplot(B2, aes(factor(node), value, fill = Typicality)) + 
  geom_bar(stat="identity") + 
  scale_fill_brewer(palette = "Paired") + 
  labs(title = "Node Centrality (Betweenness)",
       x = "Feature",
       y = "Centrality") +
  coord_flip()



```

The features with the highest absolute value z-scores are: utterance duration, speech rate, H1H2, standard deviation of H1H2, and articulation rate. 


## Build network of speakers

Here we take the most central acoustic features from the analysis above, and use them to map a network of speakers. The colors indicate whether these indiviudals were categorized by naïve raters as typical or atypical sounding. Numbers in nodes are particpant ID numbers.
```{r echo = T, results = 'hide', message=FALSE, warning = F}
library(ggplot2)
library(qgraph)
library(tidyverse)
library(igraph)

rm(list = ls())

# load and arrange data
df <- read.csv("/Users/ethan/Documents/GitHub/ASD-voice/Paper/data/FullData2.csv")


df$DX <- ifelse(df$DX == 1, "TD", "ASD")
df$naive_intuitions <- ifelse(df$rating_naive > 1.5, "Atypical", "Typical")
d <- data.frame("Utterance_dur" = df$utt_duration,
                "speech_rate" = df$speech_rate,
                "H1H2_SD" = df$H1H2_SD,
                "H1H2" = df$H1H2,
                "articulation_rate" = df$articulation_rate)

# re-arrange data so that people are nodes (column headers)
d <- t(d)
colnames(d) <- df$ID
d <- as.data.frame(d)
d <- as.data.frame(scale(d))

# graph the network of people
g <-qgraph(cor(d), layout = "spring", repulsion = 5, graph = "pcor", threshold = .08, labels = colnames(d), groups = as.factor(df$naive_intuitions), title = "Naïve intuitions - partial correlations")

g1b <-qgraph(cor(d), layout = "spring", repulsion = 5, graph = "pcor", threshold = .08, labels = colnames(d), groups = as.factor(df$DX), title = "DX - partial correlations")

g1 <- g



```

## Find subgroups of speakers
Here we use a community detection algorithm to find clusters of speakers whose acoustic speech profiles resemble one another. 
```{r echo = T, results = 'hide', message=FALSE, warning = F}


# convert to igraph object for detecting sub-groups
gi <- as.igraph(g)

# run sub-group detection. 
#Beware: Group numbers change on successive runs (seemingly even when seed is set), so take care in comparing network with results in bar plot
set.seed(42)
#w <- walktrap.community(gi)
s <- spinglass.community(gi, spins = 10)

# make data-frame with person ID and sub-group membership for reference
s2 <- data.frame("ID" = colnames(d),
                 "Community" = s$membership)

# re-plot the network, adding colors for the sub-groups found by detection algorithm
g <-qgraph(cor(d), layout = "spring", repulsion = 5, graph = "pcor", threshold = .08, labels = colnames(d), groups = as.factor(s2$Community), title = "Sub-groups (spin-glass model)")

# save plot as g2 for easy calling below
g2 <- g
plot(g2)
```

## How do the features determine the subgroups?

The subgroups include nodes that have the highest number of positive connections with other nodes within the group, and the highest number of negative connections with nodes outside the group. Here we allow for up to 10 different subgroups, but the algorithm settles on 4 as the optimal number.
```{r echo = T, results = 'hide', message=FALSE, warning = F}
# set up data for plotting bar graph
data <- data.frame("Utterance_dur" = df$utt_duration,
                "speech_rate" = df$speech_rate,
                "H1H2_SD" = df$H1H2_SD,
                "H1H2" = df$H1H2,
                "articulation_rate" = df$articulation_rate)
data <- as.data.frame(scale(data))

data$Community <- s2$Community

Com1 <- colMeans(subset(data, Community == 1))
Com2 <- colMeans(subset(data, Community == 2))
Com3 <- colMeans(subset(data, Community == 3))
Com4 <- colMeans(subset(data, Community == 4))

Community <- data.frame("SubGroup1" = Com1[1:5],
                        "Subgroup2" = Com2[1:5],
                        "Subgroup3" = Com3[1:5],
                        "Subgroup4" = Com4[1:5])

C <- data.frame(t(Community))
C$Subgroups <- as.factor(c("Group1", "Group2", "Group3", "Group4"))

library(reshape2)
C2 <- melt(C)

# save bar graph as g3 for easy calling below
g3 <- ggplot(C2, aes(Subgroups, value)) +
   geom_bar(aes(fill = variable), stat="identity") +
   theme_classic() +
   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
   ylab("z-score")

plot(g3)

```


## How do the acoustic-feature-defined subgroups correspond to perceived atypicality?
```{r}
# combine participant ID's, community membership, and naive ratings
df_soc <- read.csv("/Users/ethan/Documents/GitHub/ASD-voice/data/Soc_Lang_Database.csv")

rat_mem <- s2
rat_mem$rating <- df$rating_naive
rat_mem$clin_rating <- df$rating_clin
rat_mem$Subgroup <- as.factor(rat_mem$Community)
rat_mem$Soc_Aware_T <- df_soc$Soc_Aware_T
rat_mem$Soc_Cog_T <- df_soc$Soc_Cog_T
rat_mem$Soc_Comm_T <- df_soc$Soc_Comm_T
rat_mem$Soc_Mot_T <- df_soc$Soc_Mot_T
rat_mem$Aut_Mann_T <- df_soc$Aut_Mann_T
rat_mem$ADOS_T <- df_soc$ADOS_tot
rat_mem$SRT_total <- df_soc$SRS_Total_T
rat_mem$ASD <- df_soc$gender1M2F
rat_mem$ASD <- ifelse(rat_mem$ASD == 1, 0, 1)

ggplot(rat_mem, aes(Subgroup, rating, fill = Subgroup)) +
  geom_boxplot() +
  geom_text(aes(label = ID)) +
  theme_classic() +
  theme(legend.position="none") +
  labs(
    y = "Atypicality Rating"
  )

ggplot(rat_mem, aes(Subgroup, clin_rating, fill = Subgroup)) +
  geom_boxplot() +
  geom_text(aes(label = ID)) +
  theme_classic() +
  theme(legend.position="none") +
  labs(
    y = "Clinical Rating"
  )

sg1 <- ggplot(rat_mem, aes(Subgroup, Soc_Aware_T, fill = Subgroup)) +
  geom_boxplot() +
  theme_classic()
sg2 <- ggplot(rat_mem, aes(Subgroup, Soc_Cog_T, fill = Subgroup)) +
  geom_boxplot() +
  theme_classic()
sg3 <- ggplot(rat_mem, aes(Subgroup, Soc_Comm_T, fill = Subgroup)) +
  geom_boxplot() +
  theme_classic()
sg4 <- ggplot(rat_mem, aes(Subgroup, Soc_Mot_T, fill = Subgroup)) +
  geom_boxplot() +
  theme_classic()
sg5 <- ggplot(rat_mem, aes(Subgroup, Aut_Mann_T, fill = Subgroup)) +
  geom_boxplot() +
  theme_classic()
sg5 <- ggplot(rat_mem, aes(Subgroup, SRT_total, fill = Subgroup)) +
  geom_boxplot() +
  theme_classic()

```

```{r}
rat_mem$Subgroup <- as.factor(rat_mem$Subgroup)


mod1 <- aov(rat_mem$Soc_Aware_T ~ rat_mem$Subgroup)
mod1l <- lm(rat_mem$Soc_Aware_T ~ rat_mem$Subgroup)
summary(mod1)
psycho::analyze(mod1)
#TukeyHSD(mod1, conf.level = 0.99)

mod2 <- aov(rat_mem$Soc_Cog_T ~ rat_mem$Subgroup)
summary(mod2)
psycho::analyze(mod2)

mod3 <- aov(rat_mem$Soc_Comm_T ~ rat_mem$Subgroup)
summary(mod3)
psycho::analyze(mod3)

mod4 <- aov(rat_mem$Soc_Mot_T ~ rat_mem$Subgroup)
summary(mod4)

mod5 <- aov(rat_mem$Aut_Mann_T ~ rat_mem$Subgroup)
summary(mod5)


mod6 <- aov(rat_mem$SRT_total ~ rat_mem$Subgroup)
summary(mod6)
psycho::analyze(mod6)
TukeyHSD(mod6, conf.level = 0.99)


```


## How well do acoustic features correlate with symptom severity?
```{r}
#rm(list = ls())

library(tidyverse)
library(pander)



df <- read.csv("/Users/ethan/Documents/GitHub/ASD-voice/Paper/data/FullData2.csv")

features <- c("F0", "F0_SD", "utt_duration", "H1H2", "H1H2_SD", "speech_rate", "articulation_rate", "creak", "creak_SD", "rating_clin", "rating_naive")

d <-as.data.frame(df[, features])

#d <-as.data.frame(df[, c("utt_duration", "H1H2", "H1H2_SD", "speech_rate", "articulation_rate")] <- scale(df[, c("utt_duration", "H1H2", "H1H2_SD", "speech_rate", "articulation_rate")]))

d$ID <- df$ID

df_soc <- read.csv("/Users/ethan/Documents/GitHub/ASD-voice/data/Soc_Lang_Database.csv")
df_soc$ID <- df_soc$SUBJECT
d_soc <- df_soc %>% dplyr::select(
  SUBJECT,
  group1TD2ASD,
  Soc_Aware_T,
  Soc_Cog_T,
  Soc_Comm_T,
  Soc_Mot_T,
  Aut_Mann_T)
d_soc <- rename(d_soc, ID = SUBJECT)
d_soc[,] <- sapply(d_soc[,],as.numeric)

d <- merge(x = d, y = d_soc, by = "ID", all = TRUE)

d <- na.omit(d)
d$group1TD2ASD <- NULL
d$ID <- NULL
d <- as.data.frame(scale(d))

groups <- factor(c(rep("Pitch",2), "Rhythm", rep("Voice",2), rep("Rhythm",2), rep("Voice", 2), rep("Ratings", 2), rep("SRS",5)))
g6 <-qgraph(cor(d), layout = "spring", repulsion = 5, graph = "cor", threshold = .08, labels = colnames(d), groups = groups, label.scale.equal = TRUE, curveAll = TRUE, title = "Correlation")
#g2 <-qgraph(cor(d), layout = "spring", repulsion = 5, graph = "pcor", threshold = .08, labels = colnames(d), groups = groups, label.scale.equal = TRUE, title = "Partial Correlation", rotation = 1.658063)


pander(cor(d))

pdf("/Users/ethan/Documents/GitHub/ASD-voice/MOLA2020_abstracts/Symptom_Severity.pdf")
par(mfrow=c(2,2))
plot(g6)
#plot(g2)
dev.off()


```

```{r}
ggpubr::ggarrange(sg1, sg2, sg3, sg4,sg5, ncol = 3, nrow = 2)

rat_mem <- na.omit(rat_mem)
rat_mem[,5:11] <- sapply(rat_mem[,5:11],as.numeric)
pander(cor(rat_mem[,5:11]))
  


```


```{r}
library(ggpubr)
p1 <- ggplot(df, aes(ID, H1H2_SD, fill = DX)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = ID))

p2 <- ggplot(df, aes(ID, rating_clin, fill = DX)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = ID))

ggarrange(p1,p2, ncol = 2)
```

